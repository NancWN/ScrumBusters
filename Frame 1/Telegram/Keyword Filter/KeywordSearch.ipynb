{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NancWN/ScrumBusters/blob/main/KeywordSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJX5qK43TmPO"
      },
      "source": [
        "What can it do?:\n",
        "it takes a predefined list of keywords which is divided between pump and no_pump words. it uses the list to search trough chat data. if a match is found, the group name, the word and label is written down in a seperate list.\n",
        "\n",
        "Requirements:\n",
        "1. upload a list with Keywords you want to search for\n",
        "2. provide chat data from telegram groups in CSV format\n",
        "3. adjust the path in the code\n",
        "\n",
        "Lets go! :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "# settings\n",
        "# feel free to change settings here\n",
        "# only change other cells if you know what you are doing\n",
        "keyword_set = 'brainstorm' # choose one of 'paper', 'brainstorm', 'mixed'\n",
        "batch_number = 5\n",
        "message_path = '/Users/nancynyambura/Desktop/Digital Shaper Program/ScrumBusters/Frame 1/Telegram/data/sample/messages_batch{}_old.csv'.format(batch_number) # put in the path of the message file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "G:\\Meine Ablage\\TechLabs\\Scam Busters\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'manual_channel_list_messages.csv'"
            ]
          },
          "execution_count": 181,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# settings for soenke\n",
        "message_root = 'data/01_raw_chat/'\n",
        "%cd G:\\Meine Ablage\\TechLabs\\Scam Busters\n",
        "\n",
        "import os\n",
        "message_files = os.listdir(message_root)\n",
        "file_nr = 12\n",
        "message_path = message_root+message_files[file_nr]\n",
        "message_files[file_nr]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # run this cell to change working directory to its parent directory\n",
        "# %cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import libraries, load message data and keyword list\n",
        "import csv\n",
        "import pandas as pd \n",
        "\n",
        "#List of Keywords we want to search\n",
        "\n",
        "# lists = pd.read_csv('/Users/nancynyambura/Desktop/Digital Shaper Program/ScrumBusters/Frame 1/Telegram/Keyword Filter/references/{}_kw.csv'.format(keyword_set),index_col=0)\n",
        "# setting for soenke\n",
        "lists = pd.read_csv('references/paper_kw.csv')\n",
        "lists=pd.DataFrame(lists, columns=['pump','no_pump'])\n",
        "#lists.columns=['pump','no_pump']\n",
        "\n",
        "\n",
        "pump_words=lists[\"pump\"].dropna()\n",
        "no_pump_words=lists[\"no_pump\"].dropna()\n",
        "\n",
        "#telegram chat export (csv-file)\n",
        "searchlists=pd.read_csv(message_path, sep=',',na_values = ['no info', '.'])\n",
        "searchlists.text= searchlists.text.astype('str')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         good\n",
              "1      accumul\n",
              "2          day\n",
              "3         coin\n",
              "4     stoploss\n",
              "5          oov\n",
              "6          low\n",
              "7       signal\n",
              "8        block\n",
              "9         long\n",
              "10       price\n",
              "11        sell\n",
              "12       volum\n",
              "13      target\n",
              "14         bid\n",
              "15     current\n",
              "16         buy\n",
              "17       start\n",
              "18     bittrex\n",
              "Name: pump, dtype: object"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pump_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create dataset of all chat names and chat ids\n",
        "chat_names = searchlists.chat.unique()\n",
        "chat_ids = range(len(chat_names))\n",
        "chat_name_history = pd.DataFrame(data=[chat_names,chat_ids]).T\n",
        "chat_name_history.columns = ['chat_name','chat_id']\n",
        "\n",
        "# add the chat ids to the message dataframe\n",
        "searchlists = searchlists.merge(\n",
        "    chat_name_history,\n",
        "    how='left',\n",
        "    left_on = 'chat',\n",
        "    right_on = 'chat_name'\n",
        "    )\n",
        "searchlists = searchlists.set_index('Unnamed: 0')\n",
        "searchlists.index.name = 'row_id'\n",
        "# drop the extended chat ids\n",
        "searchlists.drop(['chat_name'],axis=1,inplace =True)\n",
        "# simplify date column\n",
        "searchlists.date = pd.to_datetime(searchlists.date).dt.tz_localize(None)\n",
        "searchlists.reset_index(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "# simple function to state if a substring was found in a string\n",
        "# this is not necessary but it's easier to understand than alternative solutions\n",
        "def key_found(key,msg):\n",
        "    if key in str(msg):\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "# iterate over keyword list\n",
        "# create new col per keyword to state if the keyword was found in the message\n",
        "for keyword in pump_words:\n",
        "    searchlists.loc[:,keyword] = [\n",
        "        key_found(keyword, msg)\n",
        "        for msg in searchlists.text\n",
        "    ]\n",
        "    \n",
        "    searchlists.text = [\n",
        "        msg.replace(keyword,'**'+keyword+'**')\n",
        "        for msg in searchlists.text\n",
        "    ]\n",
        "\n",
        "# same process for no pump words\n",
        "for keyword in no_pump_words:\n",
        "    searchlists.loc[:,keyword] = [\n",
        "        key_found(keyword, msg)\n",
        "        for msg\n",
        "        in searchlists.text\n",
        "    ]\n",
        "searchlists.text = [\n",
        "        msg.replace(keyword,'##'+keyword+'##')\n",
        "        for msg in searchlists.text\n",
        "    ]\n",
        "\n",
        "# get the number of keywords found per message\n",
        "searchlists.loc[:,'n_pump_words'] = (searchlists[pump_words]).sum(axis=1)\n",
        "searchlists.loc[:,'n_nopump_words'] = (searchlists[no_pump_words]).sum(axis=1)\n",
        "searchlists.loc[:,'n_words'] = searchlists.n_pump_words + searchlists.n_nopump_words\n",
        "\n",
        "searchlists.sort_values('n_words',ascending=False,inplace=True)\n",
        "msg_sus_df = searchlists.loc[searchlists.n_words>0][['text','date','chat','n_words']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "msg_sus_df.to_csv('data/02_suspicious_messages/sus_msgs_{id}'.format(id=message_files[file_nr][9:]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMG6W+B3hP9LZB1YYVLAYk3",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "KeywordSearch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
