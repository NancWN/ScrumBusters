{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd G:\\Meine Ablage\\TechLabs\\Scam Busters\n",
    "%cd '/Users/nancynyambura/Desktop/Digital Shaper Program'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import inspect\n",
    "\n",
    "import datetime as dt\n",
    "features_id = dt.date.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# settings to load data\n",
    "mypath = '/Users/nancynyambura/Desktop/Digital Shaper Program/ScrumBusters/Frame 1/Telegram/data/04_raw_financial/'\n",
    "\n",
    "onlyfiles = [mypath + f for f in listdir(mypath) if (isfile(join(mypath, f)))]\n",
    "\n",
    "onlyfiles = [f for f in onlyfiles if 'simplified' in f ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set threshold value for the pump indicator (max return within 1 minute)\n",
    "successful_pump_threshold = 1.1\n",
    "time_to_pump = 5\n",
    "expected_pump_row = -31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pump_status_dict = {\n",
    "    0:'failed',\n",
    "    1:'success',\n",
    "    2:'maybe - wrong time',\n",
    "    3:'maybe - low initial return',\n",
    "    4:'maybe - different reason'\n",
    "}\n",
    "\n",
    "import pickle\n",
    "with open('pump_status_dictionary.pkl', 'wb') as f:\n",
    "    pickle.dump(pump_status_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pump_success(indicator, indicator_idx, df_length):\n",
    "    if (indicator >= successful_pump_threshold) & (indicator_idx == df_length+expected_pump_row):\n",
    "        return 1\n",
    "    if (indicator >= successful_pump_threshold):\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def pump_success_indicator(file):\n",
    "    df = pd.read_csv(file)\n",
    "    high, open = df.high, df.open\n",
    "    idx_indicator = (high/open).idxmax()\n",
    "    indicator = (high/open)[idx_indicator]\n",
    "    high_max=df['high'].rolling(2).max()\n",
    "    open_max=df['open'].rolling(2).max()\n",
    "    open_max = open_max.dropna().reset_index(drop=True)\n",
    "    max_possible_return = df.iloc[-40:-25].high.max() / df.iloc[-40:-25].low.min()\n",
    "    max_5m_return = (high_max/open_max).dropna().max()\n",
    "    max_5m_return_idx = (high_max/open_max).dropna().idxmax()\n",
    "    pump_success = get_pump_success(indicator,idx_indicator,len(df))\n",
    "    return {'indicator':indicator, 'idx_indicator':idx_indicator,\n",
    "        'max_possible_return':max_possible_return, 'pump_success':pump_success}\n",
    "\n",
    "all_indicators = pd.DataFrame([\n",
    "    pump_success_indicator(file)\n",
    "    for file\n",
    "    in onlyfiles\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 0\n",
    "raw_df = pd.read_csv(onlyfiles[id])\n",
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('high, volume')\n",
    "fig.set_size_inches(18.5, 6.5)\n",
    "ax1.plot(raw_df['Unnamed: 0'], raw_df.high)\n",
    "ax2.plot(raw_df['Unnamed: 0'], raw_df.volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returns_before_pump(df,hours_to_pump):\n",
    "    '''returns the ROI if investing hours_to_pump \n",
    "    number of hours before the exit and exiting\n",
    "    time_to_pump minutes before the pump'''\n",
    "    roi = df.high.iloc[-1] / df.high.iloc[ - hours_to_pump * 60 - 1 ]\n",
    "    return roi\n",
    "\n",
    "def get_btc_volume(df,hours_to_pump):\n",
    "    '''returns the total volume for t hours \n",
    "    up until x minutes before the pump'''\n",
    "    return df.quote_asset_volume.iloc[-hours_to_pump*60-1:].sum()\n",
    "\n",
    "def get_coin_volume(df,hours_to_pump):\n",
    "    return df.volume.iloc[-hours_to_pump*60-1:].sum()\n",
    "\n",
    "def get_coin_volume_avg(df,hours_to_pump):\n",
    "    return df.volume.iloc[-hours_to_pump*60-1:].mean()\n",
    "\n",
    "def get_coin_volume_std(df,hours_to_pump):\n",
    "    return df.volume.iloc[-hours_to_pump*60-1:].std()\n",
    "\n",
    "def get_coin_volume_hourly(df,hours_to_pump):\n",
    "        return df.volume.iloc[-hours_to_pump*60-1:].sum()\n",
    "\n",
    "def get_trades_std(df,hours_to_pump):\n",
    "        return df.n_trades.iloc[-hours_to_pump*60-1:].std()\n",
    "\n",
    "\n",
    "def get_log_return(df,hours_to_pump):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full engineering for a single df\n",
    "def compute_features(df):\n",
    "    # cut off everything that will be unknown in reality\n",
    "    df_cutoff = df.iloc[:expected_pump_row-time_to_pump]\n",
    "    df_to_1h = df.iloc[:expected_pump_row-60]\n",
    "\n",
    "    # instantiate empty dict\n",
    "    features = {}\n",
    "\n",
    "    # get features which need a timespan to make sense\n",
    "    hrs = [1,3,12,24,36,48,60,72]\n",
    "    for h in hrs:\n",
    "        features[f'return_{h}hrs_to_cutoff'] = returns_before_pump(df_cutoff,h)\n",
    "        features[f'return_{h}hrs_to_1h'] = returns_before_pump(df_to_1h,h)\n",
    "        features[f'btc_volume_{h}hrs_to_cutoff'] = get_btc_volume(df_cutoff,h)\n",
    "        features[f'btc_volume_{h}hrs_to_1h'] = get_btc_volume(df_to_1h,h)\n",
    "        features[f'coin_volume_{h}hrs_to_cutoff'] = get_coin_volume(df_cutoff,h)\n",
    "        features[f'coin_volume_{h}hrs_to_1h'] = get_coin_volume(df_to_1h,h)\n",
    "        features[f'coin_volume_avg_{h}hrs_to_1h'] = get_coin_volume_avg(df_to_1h,h)\n",
    "        features[f'coin_volume_avg_{h}hrs_to_cutoff'] = get_coin_volume_avg(df_cutoff,h)\n",
    "        features[f'coin_volume_std_{h}hrs_to_1h'] = get_coin_volume_std(df_to_1h,h)\n",
    "        features[f'coin_volume_std_{h}hrs_to_cutoff'] = get_coin_volume_std(df_cutoff,h)\n",
    "        features[f'trade_std_{h}hrs_to_1h'] = get_trades_std(df_to_1h,h)\n",
    "        features[f'trade_std_{h}hrs_to_cutoff'] = get_trades_std(df_cutoff,h)\n",
    "\n",
    "    ## volume hourly score (maybe quarter hourly)\n",
    "    features[f'coin_volume_hourly_1hrs_to_1h'] = get_coin_volume_hourly(df_to_1h,1)\n",
    "    # features to be added\n",
    "    ## coin value in usd=coin price in USD\n",
    "    ## return std\n",
    "    ## pumped_before\n",
    "\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the label\n",
    "# pump column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all features\n",
    "engineered_df = pd.DataFrame([\n",
    "    compute_features(pd.read_csv(file))\n",
    "    for file\n",
    "    in onlyfiles\n",
    "])\n",
    "feature_list = engineered_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_df.loc[:,'pumped'] = all_indicators.pump_success.replace(2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add symbols to the engineered_df\n",
    "\n",
    "def get_symbol(path_str):\n",
    "    file_str=path_str[path_str.find('pump')+5:]\n",
    "    file_str = file_str[:file_str.find('_')]\n",
    "    return file_str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_df.loc[:,'symbol'] = [\n",
    "    get_symbol(path_str)\n",
    "    for path_str in onlyfiles\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get market cap data\n",
    "\n",
    "from requests import Request, Session\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "import json\n",
    "\n",
    "url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
    "parameters = {\n",
    "  'start':'1',\n",
    "  'limit':'5000',\n",
    "  'convert':'USD'\n",
    "}\n",
    "headers = {\n",
    "  'Accepts': 'application/json',\n",
    "  'X-CMC_PRO_API_KEY': '541aa958-c55e-4527-a3b4-5734f576b6bf',\n",
    "}\n",
    "\n",
    "session = Session()\n",
    "session.headers.update(headers)\n",
    "\n",
    "try:\n",
    "  response = session.get(url, params=parameters)\n",
    "  data = json.loads(response.text)\n",
    "except (ConnectionError, Timeout, TooManyRedirects) as e:\n",
    "  print(e)\n",
    "\n",
    "# unpack and simplify data\n",
    "market_cap_df = pd.DataFrame(response.json()['data'])\n",
    "unpacked = pd.DataFrame(market_cap_df.quote.tolist())\n",
    "unpacked = pd.DataFrame(unpacked.USD.tolist())\n",
    "market_cap_df.loc[:,'market_cap'] = unpacked.market_cap\n",
    "market_cap_df = market_cap_df[['symbol','market_cap','date_added']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the coin age\n",
    "market_cap_df.date_added = [\n",
    "    pd.to_datetime(date).tz_localize(None)\n",
    "    for date in market_cap_df.date_added\n",
    "]\n",
    "today = pd.to_datetime(dt.date.today())\n",
    "market_cap_df.loc[:,'coin_age'] = [\n",
    "    (today-date).days/365\n",
    "    for date in market_cap_df.date_added\n",
    "]\n",
    "# keep only relevant data\n",
    "market_cap_df = market_cap_df[['symbol','market_cap','coin_age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add market cap\n",
    "engineered_df = pd.merge(engineered_df, market_cap_df, on='symbol', how = 'left')#.drop(['Unnamed: 0', 'symbol'], axis = 1)\n",
    "engineered_df.market_cap = engineered_df.market_cap.fillna(engineered_df.market_cap.min())\n",
    "# impute missing values\n",
    "engineered_df.coin_age = engineered_df.coin_age.fillna(engineered_df.coin_age.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_df.to_csv(f'/Users/nancynyambura/Desktop/Digital Shaper Program/ScrumBusters/Frame 1/Telegram/data/05_engineered_features/{features_id}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_df.pumped.sum()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65dee9a9d1a923d78ab16c84a55db276e0248384890ce461db8ba4ddd71fba4b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('busters')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
