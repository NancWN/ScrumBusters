{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8a72dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4147e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d4cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pumpolymp.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01477c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "\n",
    "website= requests.get(url)\n",
    "website_text = website.text\n",
    "soup = BeautifulSoup(website_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "226c89f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    links.append(link.get('href'))\n",
    "    \n",
    "for link in links:\n",
    "    print(links)\n",
    "    \n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "910e46b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "  \n",
    "  \n",
    "# function to extract html document from given url\n",
    "def getHTMLdocument(url):\n",
    "      \n",
    "    # request for HTML document of given url\n",
    "    response = requests.get(url)\n",
    "      \n",
    "    # response will be provided in JSON format\n",
    "    return response.text\n",
    "  \n",
    "    \n",
    "# assign required credentials\n",
    "# assign URL\n",
    "url_to_scrape = \"https://pumpolymp.com\"\n",
    "\n",
    "\n",
    "  \n",
    "# create document\n",
    "html_document = getHTMLdocument(url_to_scrape)\n",
    "#print(test_to_scrape)\n",
    "  \n",
    "# create soap object\n",
    "soup = BeautifulSoup(html_document, 'html.parser')\n",
    "  \n",
    "  \n",
    "# find all the anchor tags with \"href\" \n",
    "# attribute starting with \"https://\"\n",
    "for link in soup.find_all('a', \n",
    "                          attrs={'href': re.compile(\"^https://\")}):\n",
    "    # display the actual urls\n",
    "    print(link.get('href')) \n",
    "print(len(link.get('href')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98d8e32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urls:  ['http://ogp.me/ns#', 'https://pumpolymp.com/img/logo_text_below_large_margin.png', 'https://pumpolymp.com/img/logo_text_below_large_margin.png', 'https://pumpolymp.com/img/logo_text_below_large_margin.png', 'https://pumpolymp.com/img/logo_text_below_large_margin.png', 'https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css', 'https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css', 'https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css', 'github.com/picturepan2/devices.css', 'https://pumpolymp.com/analytics/best-channels', 'https://pumpolymp.com/analytics/best-channels', 'https://pumpolymp.com/analytics/best-channels', 'https://www.google-analytics.com/analytics.js', 'https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js', 'https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js', 'https://t.me/BitcoinBillionaires', 'https://t.me/cryptoprofitcoach', 'https://t.me/joinchat/AAAAAE-ufWSDXHjNy2rQJA', 'https://t.me/joinchat/TlCyEpSWct1YLa7O', 'https://t.me/WallStreetBetsPumper', 'https://t.me/binancepumproys', 'https://t.me/WallStreetBetsPumper', 'https://t.me/APE_crypto', 'https://t.me/Whalesguide', 'https://t.me/BinanceWaves', 'http://www.w3.org/2000/svg', 'https://www.alexa.com/siteinfo/pumpolymp.com', 'https://www.googletagmanager.com/gtag/js?id=UA-124556455-1']\n",
      "28\n",
      "['https://t.me/BitcoinBillionaires', 'https://t.me/cryptoprofitcoach', 'https://t.me/joinchat/AAAAAE-ufWSDXHjNy2rQJA', 'https://t.me/joinchat/TlCyEpSWct1YLa7O', 'https://t.me/WallStreetBetsPumper', 'https://t.me/binancepumproys', 'https://t.me/WallStreetBetsPumper', 'https://t.me/APE_crypto', 'https://t.me/Whalesguide', 'https://t.me/BinanceWaves']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "file = open(\"/Users/syedaliraza/Downloads/Scam_data.txt\")\n",
    "#print(file.read())\n",
    "x= file.read()\n",
    "#print(x)\n",
    "def Find(x):\n",
    "  \n",
    "    # findall() has been used \n",
    "    # with valid conditions for urls in string\n",
    "    regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    url = re.findall(regex,x)      \n",
    "    return [q[0] for q in url]\n",
    "      \n",
    "# Driver Code\n",
    "\n",
    "print(\"Urls: \", Find(x))\n",
    "print(len(Find(x)))\n",
    "#print(x)\n",
    "ls = Find(x)\n",
    "#print(ls)\n",
    "matches = []\n",
    " \n",
    "for match in ls:\n",
    "    if \"https://t.me/\" in match:\n",
    "        matches.append(match)\n",
    "print(matches)\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a79653fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urls:  ['http://ogp.me/ns#', 'https://pumpolymp.com/img/logo_text_below_large_margin.png', 'https://pumpolymp.com/img/logo_text_below_large_margin.png', 'https://pumpolymp.com/img/logo_text_below_large_margin.png', 'https://pumpolymp.com/img/logo_text_below_large_margin.png', 'https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css', 'https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css', 'https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css', 'github.com/picturepan2/devices.css', 'https://pumpolymp.com/analytics/best-channels', 'https://pumpolymp.com/analytics/best-channels', 'https://pumpolymp.com/analytics/best-channels', 'https://www.google-analytics.com/analytics.js', 'https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js', 'https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js', 'https://t.me/BitcoinBillionaires', 'https://t.me/cryptoprofitcoach', 'https://t.me/joinchat/AAAAAE-ufWSDXHjNy2rQJA', 'https://t.me/joinchat/TlCyEpSWct1YLa7O', 'https://t.me/WallStreetBetsPumper', 'https://t.me/binancepumproys', 'https://t.me/WallStreetBetsPumper', 'https://t.me/APE_crypto', 'https://t.me/Whalesguide', 'https://t.me/BinanceWaves', 'http://www.w3.org/2000/svg', 'https://www.alexa.com/siteinfo/pumpolymp.com', 'https://www.googletagmanager.com/gtag/js?id=UA-124556455-1']\n",
      "28\n",
      "['https://t.me/BitcoinBillionaires', 'https://t.me/cryptoprofitcoach', 'https://t.me/joinchat/AAAAAE-ufWSDXHjNy2rQJA', 'https://t.me/joinchat/TlCyEpSWct1YLa7O', 'https://t.me/WallStreetBetsPumper', 'https://t.me/binancepumproys', 'https://t.me/WallStreetBetsPumper', 'https://t.me/APE_crypto', 'https://t.me/Whalesguide', 'https://t.me/BinanceWaves']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "file = open(\"/Users/syedaliraza/Downloads/Scam_data.txt\")\n",
    "#print(file.read())\n",
    "x= file.read()\n",
    "#print(x)\n",
    "def Find(x):\n",
    "  \n",
    "    # findall() has been used \n",
    "    # with valid conditions for urls in string\n",
    "    regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    url = re.findall(regex,x)      \n",
    "    return [q[0] for q in url]\n",
    "      \n",
    "# Driver Code\n",
    "\n",
    "print(\"Urls: \", Find(x))\n",
    "print(len(Find(x)))\n",
    "#print(x)\n",
    "ls = Find(x)\n",
    "#print(ls)\n",
    "matches = []\n",
    " \n",
    "for match in ls:\n",
    "    if \"https://t.me/\" in match:\n",
    "        matches.append(match)\n",
    "print(matches)\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d23a02d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://t.me/cryptoprofitcoach'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"/Users/syedaliraza/Downloads/Scam_data.txt\")\n",
    "#print(file.read())\n",
    "x= file.read()\n",
    "#print(x)\n",
    "def Find(x):\n",
    "  \n",
    "    # findall() has been used \n",
    "    # with valid conditions for urls in string\n",
    "    regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    url = re.findall(regex,x)      \n",
    "    return [q[0] for q in url]\n",
    "      \n",
    "# Driver Code\n",
    "\n",
    "print(\"Urls: \", Find(x))\n",
    "print(len(Find(x)))\n",
    "#print(x)\n",
    "ls = Find(x)\n",
    "#print(ls)\n",
    "matches = []\n",
    " \n",
    "for match in ls:\n",
    "    if \"https://t.me/\" in match:\n",
    "        matches.append(match)\n",
    "print(matches)\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "matcheslist = matches1.append(matches2)\n",
    "\n",
    "with open('filename.pickle', 'wb') as handle:\n",
    "    pickle.dump(matcheslist, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
